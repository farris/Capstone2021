{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 5\n",
    "f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "D7YGCrY2Ocwz"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from tor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from skimage import io\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qyc3GNmpOgY9",
    "outputId": "51235de9-ce45-46bb-ba97-3001190a44a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 512, 1024])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = io.imread('/content/drive/MyDrive/1.tif')\n",
    "\n",
    "im = torch.from_numpy(im.astype(np.float32))\n",
    "im.shape #frames,height,width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yq4MmYq-O5xS",
    "outputId": "583e1bec-ed13-4adc-9c54-8ff66f6cc052"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 512, 1024])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im.unsqueeze_(0).shape #null(C),frames,height,width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lZ1d7bLSO8cu",
    "outputId": "9867dc1a-2897-43db-fa8d-c6c31bb6ce8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 512, 512, 1024])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [im for i in range(4)]\n",
    "data = torch.stack(data)\n",
    "data.shape #batch_size,null(C),frames,height,width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "g51b3lX0O_Dk"
   },
   "outputs": [],
   "source": [
    "ICP = [30,40,50,60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-J6qOZ6gPA0f",
    "outputId": "82a5a655-e56a-4a04-d19c-764701590271"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = [data]+[ICP]\n",
    "len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "RqLnlsXwPE8C"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(torch.nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    \n",
    "    super(CNN, self).__init__()\n",
    "    \n",
    "    ######################################################\n",
    "    #inputs###############################################\n",
    "    self.c1_out = 2                                     ##\n",
    "                                                        ##\n",
    "    self.c2_out = 15                                    ##\n",
    "                                                        ##\n",
    "    self.c3_out = 12                                    ##\n",
    "                                                        ##\n",
    "    self.c4_out = 5                                     ##\n",
    "    ######################################################\n",
    "\n",
    "\n",
    "    #1st layer ###########################################\n",
    "    self.conv1 = nn.Conv3d(in_channels = 1, out_channels = self.c1_out,\\\n",
    "                           kernel_size = (5,5,5), stride=(30,30,30), padding=0) ## frames \n",
    "    #relu\n",
    "\n",
    "    \n",
    "    ######################################################\n",
    "\n",
    "\n",
    "    #Linear layer ########################################\n",
    "    self.fc1 = nn.Linear(2* 17* 17* 34, 1)\n",
    "    #relu\n",
    "    ######################################################\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = F.relu(self.conv1(x))\n",
    "    print('-----')\n",
    "    print(out.shape)\n",
    "    out = out.view(-1, out.size()[1] * out.size()[2] * out.size()[3] * out.size()[4])\n",
    "    out = F.relu(self.fc1(out))\n",
    "    print('-----')\n",
    "    print(out.shape)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "z0MnytYyPGY2",
    "outputId": "60cd3c12-9505-4444-e8d5-1e2dc3a1c068"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "torch.Size([4, 2, 17, 17, 34])\n",
      "-----\n",
      "torch.Size([4, 1])\n",
      "tensor([[13.0931],\n",
      "        [13.0931],\n",
      "        [13.0931],\n",
      "        [13.0931]], grad_fn=<ReluBackward0>)\n",
      "[30, 40, 50, 60]\n",
      "tensor(1143.0482, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([4, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-bd8fd87a34a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mtotal_train_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_loss_and_correct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mtotal_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-bd8fd87a34a1>\u001b[0m in \u001b[0;36mget_loss_and_correct\u001b[0;34m(model, batch, criterion, device)\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: eq() received an invalid combination of arguments - got (Tensor, list), but expected one of:\n * (Tensor input, Tensor other, *, Tensor out)\n * (Tensor input, Number other, *, Tensor out)\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def get_loss_and_correct(model, batch, criterion, device):\n",
    "  # Implement forward pass and loss calculation for one batch.\n",
    "  # Remember to move the batch to device.\n",
    "  # \n",
    "  # Return a tuple:\n",
    "  # - loss for the batch (Tensor)\n",
    "  # - number of correctly classified examples in the batch (Tensor)\n",
    "\n",
    "  imgs = batch[0]\n",
    "\n",
    "  labels = batch[1]\n",
    "\n",
    "  outputs = model(imgs)\n",
    "  print(outputs)\n",
    "  print(labels)\n",
    "  loss = criterion(outputs,torch.tensor(labels))\n",
    "  print(loss)\n",
    "  preds = outputs.data.max(1, keepdim=True)[1]\n",
    "\n",
    "  return (loss,torch.eq(preds.flatten(),labels).sum())\n",
    "\n",
    "\n",
    "def step(loss, optimizer):\n",
    "  # Implement backward pass and update.\n",
    "  # TODO\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  \n",
    "model = CNN()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.train()\n",
    "\n",
    "total_train_loss = 0.0\n",
    "total_train_correct = 0.0\n",
    "  \n",
    "loss, correct = get_loss_and_correct(model, batch, criterion, device = None)\n",
    "step(loss, optimizer)\n",
    "total_train_loss += loss.item()\n",
    "total_train_correct += correct.item()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Monkey_Test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('miniconda3': virtualenv)",
   "name": "python395jvsc74a57bd042f7b0564c77de6ce915feb9727aeda8693770024e57769567d8b5b3a202d8a4"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "42f7b0564c77de6ce915feb9727aeda8693770024e57769567d8b5b3a202d8a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}