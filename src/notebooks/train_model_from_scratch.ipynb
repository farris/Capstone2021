{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_model_from_scratch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1496e60de8d24b4a9d17dcfeb9c7468c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a4ad52d0565d4007b31d321dd7e295c2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_afd99994c80b431f9b034c035ac64c29",
              "IPY_MODEL_c82491a67a0242ad8e0943a9b3c41f0f",
              "IPY_MODEL_7c55161733e84756b75a86b01f8419a2"
            ]
          }
        },
        "a4ad52d0565d4007b31d321dd7e295c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "afd99994c80b431f9b034c035ac64c29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a74b84fa8bfe4fe89508943e5ec2fa2d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4d19efdd722f4ec59e67121984f2c34b"
          }
        },
        "c82491a67a0242ad8e0943a9b3c41f0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d49f2bea19f44779a94c96cfd8bbfdff",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7eb37ec414c04494a33121b9bf53d696"
          }
        },
        "7c55161733e84756b75a86b01f8419a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9705665c5ca84464af003c1b95291400",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:03&lt;00:00, 53200135.15it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0cc5cc7b2253455996fde91c81654075"
          }
        },
        "a74b84fa8bfe4fe89508943e5ec2fa2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4d19efdd722f4ec59e67121984f2c34b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d49f2bea19f44779a94c96cfd8bbfdff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7eb37ec414c04494a33121b9bf53d696": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9705665c5ca84464af003c1b95291400": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0cc5cc7b2253455996fde91c81654075": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c0fce71959974420bc56c5b018d75c3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_86c383bf6e194b058a3bd94afd3575eb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fb80c9ee148d4f04ad2d2339f48a5aac",
              "IPY_MODEL_96163615670c4621b23d650dd6e580be",
              "IPY_MODEL_7fd094effb224ea6a93484ec148b3dc5"
            ]
          }
        },
        "86c383bf6e194b058a3bd94afd3575eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fb80c9ee148d4f04ad2d2339f48a5aac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3b133e0c0b21430ca4e1067fe62b65a8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 16%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2ff1890e282f4f4589a4155cd055f416"
          }
        },
        "96163615670c4621b23d650dd6e580be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_36802fa0bab34d7bbb2d0e2d66379d2e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 50,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 8,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b1a027d26a584ba386d4d85081d1fbc2"
          }
        },
        "7fd094effb224ea6a93484ec148b3dc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_78e4e55559ea46f9b3f32f4a62bc1346",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8/50 [01:32&lt;07:11, 10.27s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7ff7fef92e2743838aa75d043e264f94"
          }
        },
        "3b133e0c0b21430ca4e1067fe62b65a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2ff1890e282f4f4589a4155cd055f416": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36802fa0bab34d7bbb2d0e2d66379d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b1a027d26a584ba386d4d85081d1fbc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "78e4e55559ea46f9b3f32f4a62bc1346": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7ff7fef92e2743838aa75d043e264f94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-QRDh739EUA"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgPnjBXs9Gff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d7c21d8-3438-4cb1-9c35-547a3b746127"
      },
      "source": [
        "# colab specific imports\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "# set up code and symlinks\n",
        "if not os.path.exists('Capstone2021'):\n",
        "  os.system('git clone https://github.com/Bulbasaurzc/Capstone2021')\n",
        "  os.system('ln -s /content/gdrive/MyDrive/\"CDS Capstone Project\"/Data/torch_arrays_128/ Capstone2021/data/')\n",
        "  os.system('ln -s /content/gdrive/MyDrive/\"CDS Capstone Project\"/Data/Raw Capstone2021/data/')\n",
        "  os.system('ln -s /content/gdrive/MyDrive/\"CDS Capstone Project\"/Data/models Capstone2021/models/')\n",
        "os.chdir('Capstone2021')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGrm8TtBV_pU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4edd30f-fd5a-4daa-bdc1-1cc88c3e5270"
      },
      "source": [
        "import os \n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "import json\n",
        "import cv2\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "seed = 12345\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "from src.data.torch_utils import MonkeyEyeballsDataset\n",
        "from src.models.from_scratch import resnet_for_multimodal_regression as resnet\n",
        "\n",
        "def train(dataloader_train, \n",
        "          dataloader_val, \n",
        "          model, \n",
        "          optimizer, \n",
        "          scheduler, \n",
        "          val_interval,\n",
        "          save_interval, \n",
        "          save_folder,\n",
        "          warm_start_epoch=0,\n",
        "          loss=nn.MSELoss(reduction='sum'), \n",
        "          total_epochs=100):\n",
        "    # settings\n",
        "    batches_per_epoch = len(dataloader_train)\n",
        "    print('{} epochs in total, {} batches per epoch'.format(total_epochs, batches_per_epoch))\n",
        "\n",
        "    if device == 'cuda':\n",
        "      loss = loss.to(device)\n",
        "        \n",
        "    model.train()\n",
        "    train_time_sp = time.time()\n",
        "\n",
        "    for epoch in range(warm_start_epoch, total_epochs):\n",
        "        print('Start epoch {}'.format(epoch))\n",
        "        \n",
        "        for batch_id, batch_data in enumerate(dataloader_train):\n",
        "            # getting data batch\n",
        "            batch_id_sp = epoch * batches_per_epoch + batch_id\n",
        "            icp = batch_data['icp'].float().unsqueeze(1)\n",
        "            iop = batch_data['iop'].float()\n",
        "            scan = batch_data['scan'].float()\n",
        "\n",
        "            if device == 'cuda': \n",
        "                scan = scan.to(device)\n",
        "\n",
        "            # standardize input\n",
        "            scan = (scan - 30) / 19\n",
        "            icp = (icp - 15) / 11 \n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            # add fake channel dimension as 5-D input is expected\n",
        "            preds = model(scan.unsqueeze(1))\n",
        "            \n",
        "            # calculating loss\n",
        "            loss_value = loss(preds, icp)\n",
        "            loss_value.backward()                \n",
        "            optimizer.step()\n",
        "\n",
        "            avg_batch_time = (time.time() - train_time_sp) / (1 + batch_id_sp)\n",
        "            print(\n",
        "                'Batch: {}-{} ({}), loss = {:.3f}, avg_batch_time = {:.3f}'\\\n",
        "                .format(epoch, batch_id, batch_id_sp, loss_value, avg_batch_time))\n",
        "          \n",
        "            # get validation loss\n",
        "            if batch_id_sp % val_interval == 0:\n",
        "                model.eval()\n",
        "                print('')\n",
        "                print('Validating...')\n",
        "                for batch_id_val, batch_data_val in enumerate(dataloader_val):\n",
        "                    icp_val = batch_data_val['icp'].float().unsqueeze(1)\n",
        "                    iop_val = batch_data_val['iop'].float()\n",
        "                    \n",
        "\n",
        "                    scan_val = batch_data_val['scan'].float()\n",
        "                    scan_val = (scan_val - 30) / 19\n",
        "                    icp_val = (icp_val - 15) / 11\n",
        "\n",
        "                    if device == 'cuda': \n",
        "                        scan_val = scan_val.to(device)\n",
        "                    preds_val = model(scan_val)\n",
        "                    loss_value_val = loss(preds_val, icp_val)\n",
        "                    \n",
        "                    print('Loss on validation: {:.3f}'.format(loss_value_val))\n",
        "                    print('')\n",
        "                \n",
        "                model.train()\n",
        "\n",
        "            # save model\n",
        "            if batch_id_sp != 0 and batch_id_sp % save_interval == 0:\n",
        "                model_save_path = os.path.join(save_folder, 'epoch_{}_batch_{}.pth.tar'\\\n",
        "                                               .format(epoch, batch_id))\n",
        "                model_save_dir = os.path.dirname(model_save_path)\n",
        "                if not os.path.exists(model_save_dir):\n",
        "                    os.makedirs(model_save_dir)\n",
        "                \n",
        "                print('Save checkpoints: epoch = {}, batch_id = {}'.format(epoch, batch_id)) \n",
        "                torch.save({\n",
        "                            'epoch': epoch,\n",
        "                            'batch_id': batch_id,\n",
        "                            'state_dict': model.state_dict(),\n",
        "                            'optimizer': optimizer.state_dict()},\n",
        "                            model_save_path)\n",
        "        scheduler.step()\n",
        "        print('lr = {}'.format(scheduler.get_lr()))\n",
        "                           \n",
        "    print('Finished training')  \n",
        "\n",
        "labels = pd.read_csv('data/monkey_data.csv')\n",
        "labels = labels[labels['torch_present'] & ~labels['icp'].isnull() & ~labels['iop'].isnull() & labels['icp'] > 0] \n",
        "labels['icp'] = labels['icp'].astype('float')\n",
        "labels['iop'] = labels['iop'].astype('float')\n",
        "train_labels = labels[labels['monkey_id'] != 14]\n",
        "# 8 handpicked examples \n",
        "val_examples = [1751, 1754, 1761, 1766]\n",
        "val_labels = labels[labels['id'].isin(val_examples)]\n",
        "\n",
        "med_train = MonkeyEyeballsDataset('data/torch_arrays_128', train_labels)\n",
        "med_val = MonkeyEyeballsDataset('data/torch_arrays_128', val_labels)\n",
        "\n",
        "dataloader_train = DataLoader(med_train, batch_size=8, num_workers=2, shuffle=True, pin_memory=True) \n",
        "dataloader_val = DataLoader(med_val, batch_size=4, num_workers=2, shuffle=False, pin_memory=True)\n",
        "\n",
        "model = resnet.resnet10(sample_input_D=128, sample_input_H=128, sample_input_W=512)\n",
        "EPOCHS = 100\n",
        "OPTIMIZER = torch.optim.SGD(model.parameters(), lr=1e-5, momentum=0.9, weight_decay=1e-3)\n",
        "SCHEDULER = lr_scheduler.ExponentialLR(OPTIMIZER, gamma=0.99)\n",
        "LOSS = nn.MSELoss(reduction='sum')\n",
        "\n",
        "# load in in case of warm start\n",
        "warm_start = torch.load('models/models/epoch_0_batch_100.pth.tar')\n",
        "model.load_state_dict(warm_start['state_dict'])\n",
        "OPTIMIZER.load_state_dict(warm_start['optimizer'])\n",
        "\n",
        "if warm_start.get('epoch') is not None:\n",
        "    current_epoch = warm_start.get('epoch')\n",
        "else:\n",
        "    current_epoch = 0\n",
        "\n",
        "train(dataloader_train=dataloader_train, \n",
        "      dataloader_val=dataloader_val,\n",
        "      model=model, \n",
        "      optimizer=OPTIMIZER, \n",
        "      scheduler=SCHEDULER, \n",
        "      total_epochs=EPOCHS, \n",
        "      warm_start_epoch=current_epoch,\n",
        "      save_interval=25, \n",
        "      save_folder='models/models/run_11_28_2021',\n",
        "      val_interval=10,\n",
        "      loss=LOSS)    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Capstone2021/src/models/from_scratch/resnet_for_multimodal_regression.py:148: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
            "  m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 epochs in total, 150 batches per epoch\n",
            "Start epoch 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpGBURoccZXo",
        "outputId": "08bc22ac-150b-4b0c-fa29-cbd285c77b47"
      },
      "source": [
        "i = 0\n",
        "for batch_id, batch_data in enumerate(dataloader_train):\n",
        "    i+=1\n",
        "    if i == 1:\n",
        "        break\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suH6-FWVDXdK",
        "outputId": "954f1324-712f-430b-9a5a-b061d0399ce4"
      },
      "source": [
        "import os \n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import torch\n",
        "import json\n",
        "import cv2\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "seed = 12345\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# colab specific imports\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "worksheet = gc.open('Monkey Data').sheet1\n",
        "rows = worksheet.get_all_values()\n",
        "data = pd.DataFrame.from_records(rows[1:])\n",
        "data.columns = rows[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXa4g4D8S9Jy"
      },
      "source": [
        "root_dir = 'gdrive/My Drive/CDS Capstone Project/Data/'\n",
        "data_dir = os.path.join(root_dir, 'torch_arrays_128')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KzLUR47EcvN"
      },
      "source": [
        "Build dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddbmRRYzk4Uc"
      },
      "source": [
        "from torch_utils import MonkeyEyeballsDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJMG1IY3TlQB"
      },
      "source": [
        "torch_present = [int(s.strip('.pt')) for s in os.listdir(data_dir)]\n",
        "keywords = ['Pre', 'pre', 'Norm', 'norm']\n",
        "labels = data\\\n",
        "  [data['id'].astype(int).isin(torch_present)]\\\n",
        "  [['id', 'iop', 'icp']]\n",
        "labels['iop'] = np.where(labels['iop'].isin(keywords), '', labels['iop'])\n",
        "labels['icp'] = np.where(labels['icp'].isin(keywords), '', labels['icp'])\n",
        "labels = labels.replace(r'^\\s*$', np.nan, regex=True)\n",
        "labels['icp'] = labels['icp'].astype('float')\n",
        "labels['iop'] = labels['iop'].astype('float')\n",
        "labels = labels.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj30COFZXMTy"
      },
      "source": [
        "med = MonkeyEyeballsDataset(data_dir, labels)\n",
        "dataloader = DataLoader(med, batch_size=8, num_workers=4, shuffle=True, pin_memory=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64C9inkt3bEY",
        "outputId": "55a93d2f-46b9-44ca-bdef-7c81eb2213eb"
      },
      "source": [
        "labels_toy = labels.sample(8)\n",
        "print(labels_toy['icp'])\n",
        "med_toy = MonkeyEyeballsDataset(data_dir, labels_toy)\n",
        "dataloader_toy = DataLoader(med_toy, batch_size=8, shuffle=False, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "121     3.0\n",
            "703    21.0\n",
            "167    10.0\n",
            "622    21.0\n",
            "385     5.0\n",
            "165    10.0\n",
            "790    30.0\n",
            "142    24.0\n",
            "Name: icp, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0JEGwivE7lE"
      },
      "source": [
        "Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wieIiMeje8ix",
        "outputId": "7e5006c7-b50f-49cf-d86d-82232d7c4c3c"
      },
      "source": [
        "import resnet_for_multimodal_regression as resnet\n",
        "model = resnet.resnet10(sample_input_D=128,\n",
        "                 sample_input_H=128,\n",
        "                 sample_input_W=512)\n",
        "if device == 'cuda':\n",
        "  model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/resnet_for_multimodal_regression.py:148: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
            "  m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwtYS2VwE8j-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "9bb2bdee-8a76-48fa-81d8-4cc5be788e3e"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "from scipy import ndimage\n",
        "import os\n",
        "import resnet_for_multimodal_regression as resnet\n",
        "\n",
        "EPOCHS = 1\n",
        "OPTIMIZER = torch.optim.SGD(model.parameters(), lr=1e-5, momentum=0.9, weight_decay=1e-3)\n",
        "SCHEDULER = lr_scheduler.ExponentialLR(OPTIMIZER, gamma=0.99)\n",
        "LOSS = nn.MSELoss(reduction='sum')\n",
        "\n",
        "def train(data_loader, model, optimizer, scheduler, total_epochs, save_interval, save_folder, loss):\n",
        "    # settings\n",
        "    batches_per_epoch = len(data_loader)\n",
        "    print('{} epochs in total, {} batches per epoch'.format(total_epochs, batches_per_epoch))\n",
        "\n",
        "    if device == 'cuda':\n",
        "      loss = loss.to(device)\n",
        "        \n",
        "    model.train()\n",
        "    train_time_sp = time.time()\n",
        "    for epoch in range(total_epochs):\n",
        "        print('Start epoch {}'.format(epoch))\n",
        "        \n",
        "        for batch_id, batch_data in enumerate(data_loader):\n",
        "            # getting data batch\n",
        "            batch_id_sp = epoch * batches_per_epoch + batch_id\n",
        "            icp = batch_data['icp'].float().unsqueeze(1)\n",
        "            iop = batch_data['iop'].float()\n",
        "            scan = batch_data['scan'].float()\n",
        "\n",
        "            if device == 'cuda': \n",
        "                scan = scan.to(device)\n",
        "\n",
        "            # standardize input\n",
        "            scan = (scan - 30) / 19\n",
        "            icp = (icp - 15) / 11 \n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            # add fake channel dimension as 5-D input is expected\n",
        "            preds = model(scan.unsqueeze(1))\n",
        "            \n",
        "            # calculating loss\n",
        "            loss_value = loss(preds, icp)\n",
        "            loss_value.backward()                \n",
        "            optimizer.step()\n",
        "\n",
        "            avg_batch_time = (time.time() - train_time_sp) / (1 + batch_id_sp)\n",
        "            print(\n",
        "                    'Batch: {}-{} ({}), loss = {:.3f}, avg_batch_time = {:.3f}'\\\n",
        "                    .format(epoch, batch_id, batch_id_sp, loss_value, avg_batch_time))\n",
        "          \n",
        "            # save model\n",
        "            if batch_id_sp != 0 and batch_id_sp % save_interval == 0:\n",
        "                model_save_path = os.path.join(save_folder, 'epoch_{}_batch_{}.pth.tar'\\\n",
        "                                               .format(epoch, batch_id))\n",
        "                model_save_dir = os.path.dirname(model_save_path)\n",
        "                if not os.path.exists(model_save_dir):\n",
        "                    os.makedirs(model_save_dir)\n",
        "                \n",
        "                print('Save checkpoints: epoch = {}, batch_id = {}'.format(epoch, batch_id)) \n",
        "                torch.save({\n",
        "                            'epoch': epoch,\n",
        "                            'batch_id': batch_id,\n",
        "                            'state_dict': model.state_dict(),\n",
        "                            'optimizer': optimizer.state_dict()},\n",
        "                            model_save_path)\n",
        "        scheduler.step()\n",
        "        print('lr = {}'.format(scheduler.get_lr()))\n",
        "                           \n",
        "    print('Finished training')            "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-49dbdb051ee0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mndimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mresnet_for_multimodal_regression\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'resnet_for_multimodal_regression'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58txCEh35lU9",
        "outputId": "b77331fe-ac1a-47ea-9bb8-072e944d6082"
      },
      "source": [
        "train(data_loader=dataloader, \n",
        "      model=model, \n",
        "      optimizer=OPTIMIZER, \n",
        "      scheduler=SCHEDULER, \n",
        "      total_epochs=10, \n",
        "      save_interval=100, \n",
        "      save_folder=os.path.join(root_dir, 'models'),\n",
        "      loss=LOSS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 epochs in total, 125 batches per epoch\n",
            "Start epoch 0\n",
            "Batch: 0-0 (0), loss = 7.256, avg_batch_time = 137.217\n",
            "Batch: 0-1 (1), loss = 15.114, avg_batch_time = 129.703\n",
            "Batch: 0-2 (2), loss = 6.264, avg_batch_time = 126.608\n",
            "Batch: 0-3 (3), loss = 17.440, avg_batch_time = 124.792\n",
            "Batch: 0-4 (4), loss = 6.694, avg_batch_time = 123.639\n",
            "Batch: 0-5 (5), loss = 7.626, avg_batch_time = 122.969\n",
            "Batch: 0-6 (6), loss = 7.398, avg_batch_time = 122.258\n",
            "Batch: 0-7 (7), loss = 12.130, avg_batch_time = 121.907\n",
            "Batch: 0-8 (8), loss = 6.731, avg_batch_time = 121.434\n",
            "Batch: 0-9 (9), loss = 11.450, avg_batch_time = 121.096\n",
            "Batch: 0-10 (10), loss = 11.122, avg_batch_time = 120.706\n",
            "Batch: 0-11 (11), loss = 8.668, avg_batch_time = 120.283\n",
            "Batch: 0-12 (12), loss = 16.955, avg_batch_time = 120.129\n",
            "Batch: 0-13 (13), loss = 6.261, avg_batch_time = 120.009\n",
            "Batch: 0-14 (14), loss = 7.751, avg_batch_time = 119.861\n",
            "Batch: 0-15 (15), loss = 5.457, avg_batch_time = 119.828\n",
            "Batch: 0-16 (16), loss = 6.804, avg_batch_time = 119.860\n",
            "Batch: 0-17 (17), loss = 12.179, avg_batch_time = 119.797\n",
            "Batch: 0-18 (18), loss = 7.959, avg_batch_time = 119.747\n",
            "Batch: 0-19 (19), loss = 4.357, avg_batch_time = 119.716\n",
            "Batch: 0-20 (20), loss = 3.942, avg_batch_time = 119.677\n",
            "Batch: 0-21 (21), loss = 4.570, avg_batch_time = 119.584\n",
            "Batch: 0-22 (22), loss = 3.454, avg_batch_time = 119.450\n",
            "Batch: 0-23 (23), loss = 2.897, avg_batch_time = 119.381\n",
            "Batch: 0-24 (24), loss = 6.638, avg_batch_time = 119.310\n",
            "Batch: 0-25 (25), loss = 3.183, avg_batch_time = 119.319\n",
            "Batch: 0-26 (26), loss = 9.741, avg_batch_time = 119.266\n",
            "Batch: 0-27 (27), loss = 8.645, avg_batch_time = 119.258\n",
            "Batch: 0-28 (28), loss = 5.685, avg_batch_time = 119.224\n",
            "Batch: 0-29 (29), loss = 7.717, avg_batch_time = 119.178\n",
            "Batch: 0-30 (30), loss = 4.308, avg_batch_time = 119.093\n",
            "Batch: 0-31 (31), loss = 2.333, avg_batch_time = 119.048\n",
            "Batch: 0-32 (32), loss = 6.635, avg_batch_time = 118.927\n",
            "Batch: 0-33 (33), loss = 14.383, avg_batch_time = 118.816\n",
            "Batch: 0-34 (34), loss = 3.743, avg_batch_time = 118.744\n",
            "Batch: 0-35 (35), loss = 9.577, avg_batch_time = 118.665\n",
            "Batch: 0-36 (36), loss = 2.087, avg_batch_time = 118.589\n",
            "Batch: 0-37 (37), loss = 3.365, avg_batch_time = 118.558\n",
            "Batch: 0-38 (38), loss = 11.501, avg_batch_time = 118.485\n",
            "Batch: 0-39 (39), loss = 14.796, avg_batch_time = 118.480\n",
            "Batch: 0-40 (40), loss = 1.218, avg_batch_time = 118.472\n",
            "Batch: 0-41 (41), loss = 5.082, avg_batch_time = 118.433\n",
            "Batch: 0-42 (42), loss = 9.266, avg_batch_time = 118.419\n",
            "Batch: 0-43 (43), loss = 3.574, avg_batch_time = 118.441\n",
            "Batch: 0-44 (44), loss = 14.966, avg_batch_time = 118.429\n",
            "Batch: 0-45 (45), loss = 3.729, avg_batch_time = 118.436\n",
            "Batch: 0-46 (46), loss = 14.002, avg_batch_time = 118.465\n",
            "Batch: 0-47 (47), loss = 2.829, avg_batch_time = 118.463\n",
            "Batch: 0-48 (48), loss = 8.577, avg_batch_time = 118.465\n",
            "Batch: 0-49 (49), loss = 9.841, avg_batch_time = 118.506\n",
            "Batch: 0-50 (50), loss = 9.126, avg_batch_time = 118.524\n",
            "Batch: 0-51 (51), loss = 3.597, avg_batch_time = 118.552\n",
            "Batch: 0-52 (52), loss = 5.529, avg_batch_time = 118.580\n",
            "Batch: 0-53 (53), loss = 16.276, avg_batch_time = 118.566\n",
            "Batch: 0-54 (54), loss = 8.599, avg_batch_time = 118.549\n",
            "Batch: 0-55 (55), loss = 3.217, avg_batch_time = 118.545\n",
            "Batch: 0-56 (56), loss = 7.171, avg_batch_time = 118.531\n",
            "Batch: 0-57 (57), loss = 6.488, avg_batch_time = 118.517\n",
            "Batch: 0-58 (58), loss = 14.375, avg_batch_time = 118.501\n",
            "Batch: 0-59 (59), loss = 3.631, avg_batch_time = 118.486\n",
            "Batch: 0-60 (60), loss = 7.708, avg_batch_time = 118.466\n",
            "Batch: 0-61 (61), loss = 12.655, avg_batch_time = 118.473\n",
            "Batch: 0-62 (62), loss = 9.465, avg_batch_time = 118.453\n",
            "Batch: 0-63 (63), loss = 3.584, avg_batch_time = 118.443\n",
            "Batch: 0-64 (64), loss = 10.222, avg_batch_time = 118.457\n",
            "Batch: 0-65 (65), loss = 6.870, avg_batch_time = 118.465\n",
            "Batch: 0-66 (66), loss = 4.880, avg_batch_time = 118.464\n",
            "Batch: 0-67 (67), loss = 10.713, avg_batch_time = 118.499\n",
            "Batch: 0-68 (68), loss = 15.683, avg_batch_time = 118.506\n",
            "Batch: 0-69 (69), loss = 10.320, avg_batch_time = 118.524\n",
            "Batch: 0-70 (70), loss = 8.131, avg_batch_time = 118.543\n",
            "Batch: 0-71 (71), loss = 2.637, avg_batch_time = 118.556\n",
            "Batch: 0-72 (72), loss = 5.149, avg_batch_time = 118.568\n",
            "Batch: 0-73 (73), loss = 7.135, avg_batch_time = 118.593\n",
            "Batch: 0-74 (74), loss = 5.163, avg_batch_time = 118.610\n",
            "Batch: 0-75 (75), loss = 2.307, avg_batch_time = 118.632\n",
            "Batch: 0-76 (76), loss = 2.814, avg_batch_time = 118.656\n",
            "Batch: 0-77 (77), loss = 10.681, avg_batch_time = 118.677\n",
            "Batch: 0-78 (78), loss = 6.654, avg_batch_time = 118.740\n",
            "Batch: 0-79 (79), loss = 3.290, avg_batch_time = 118.785\n",
            "Batch: 0-80 (80), loss = 2.223, avg_batch_time = 118.814\n",
            "Batch: 0-81 (81), loss = 15.274, avg_batch_time = 118.855\n",
            "Batch: 0-82 (82), loss = 17.481, avg_batch_time = 118.893\n",
            "Batch: 0-83 (83), loss = 4.979, avg_batch_time = 118.903\n",
            "Batch: 0-84 (84), loss = 12.209, avg_batch_time = 118.916\n",
            "Batch: 0-85 (85), loss = 8.792, avg_batch_time = 118.928\n",
            "Batch: 0-86 (86), loss = 4.558, avg_batch_time = 118.927\n",
            "Batch: 0-87 (87), loss = 12.348, avg_batch_time = 118.951\n",
            "Batch: 0-88 (88), loss = 14.900, avg_batch_time = 118.973\n",
            "Batch: 0-89 (89), loss = 6.471, avg_batch_time = 118.986\n",
            "Batch: 0-90 (90), loss = 6.983, avg_batch_time = 118.999\n",
            "Batch: 0-91 (91), loss = 10.694, avg_batch_time = 119.014\n",
            "Batch: 0-92 (92), loss = 7.555, avg_batch_time = 119.023\n",
            "Batch: 0-93 (93), loss = 3.862, avg_batch_time = 119.037\n",
            "Batch: 0-94 (94), loss = 9.248, avg_batch_time = 119.058\n",
            "Batch: 0-95 (95), loss = 12.966, avg_batch_time = 119.088\n",
            "Batch: 0-96 (96), loss = 9.821, avg_batch_time = 119.127\n",
            "Batch: 0-97 (97), loss = 8.455, avg_batch_time = 119.163\n",
            "Batch: 0-98 (98), loss = 17.913, avg_batch_time = 119.189\n",
            "Batch: 0-99 (99), loss = 7.567, avg_batch_time = 119.226\n",
            "Batch: 0-100 (100), loss = 7.090, avg_batch_time = 119.257\n",
            "Save checkpoints: epoch = 0, batch_id = 100\n",
            "Batch: 0-101 (101), loss = 6.654, avg_batch_time = 119.294\n",
            "Batch: 0-102 (102), loss = 14.662, avg_batch_time = 119.316\n",
            "Batch: 0-103 (103), loss = 3.156, avg_batch_time = 119.345\n",
            "Batch: 0-104 (104), loss = 5.250, avg_batch_time = 119.357\n",
            "Batch: 0-105 (105), loss = 7.917, avg_batch_time = 119.373\n",
            "Batch: 0-106 (106), loss = 6.971, avg_batch_time = 119.386\n",
            "Batch: 0-107 (107), loss = 8.579, avg_batch_time = 119.395\n",
            "Batch: 0-108 (108), loss = 9.509, avg_batch_time = 119.404\n",
            "Batch: 0-109 (109), loss = 8.691, avg_batch_time = 119.420\n",
            "Batch: 0-110 (110), loss = 11.487, avg_batch_time = 119.424\n",
            "Batch: 0-111 (111), loss = 8.973, avg_batch_time = 119.424\n",
            "Batch: 0-112 (112), loss = 7.418, avg_batch_time = 119.433\n",
            "Batch: 0-113 (113), loss = 6.746, avg_batch_time = 119.464\n",
            "Batch: 0-114 (114), loss = 14.582, avg_batch_time = 119.479\n",
            "Batch: 0-115 (115), loss = 16.983, avg_batch_time = 119.501\n",
            "Batch: 0-116 (116), loss = 8.543, avg_batch_time = 119.512\n",
            "Batch: 0-117 (117), loss = 8.383, avg_batch_time = 119.522\n",
            "Batch: 0-118 (118), loss = 11.220, avg_batch_time = 119.506\n",
            "Batch: 0-119 (119), loss = 6.402, avg_batch_time = 119.482\n",
            "Batch: 0-120 (120), loss = 5.191, avg_batch_time = 119.458\n",
            "Batch: 0-121 (121), loss = 4.224, avg_batch_time = 119.443\n",
            "Batch: 0-122 (122), loss = 9.820, avg_batch_time = 119.437\n",
            "Batch: 0-123 (123), loss = 9.690, avg_batch_time = 119.432\n",
            "Batch: 0-124 (124), loss = 7.095, avg_batch_time = 118.715\n",
            "lr = [9.801e-06]\n",
            "Start epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:573: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch: 1-0 (125), loss = 6.146, avg_batch_time = 118.885\n",
            "Batch: 1-1 (126), loss = 4.650, avg_batch_time = 118.920\n",
            "Batch: 1-2 (127), loss = 8.485, avg_batch_time = 118.950\n",
            "Batch: 1-3 (128), loss = 7.275, avg_batch_time = 118.969\n",
            "Batch: 1-4 (129), loss = 7.095, avg_batch_time = 118.995\n",
            "Batch: 1-5 (130), loss = 8.246, avg_batch_time = 119.014\n",
            "Batch: 1-6 (131), loss = 7.572, avg_batch_time = 119.042\n",
            "Batch: 1-7 (132), loss = 4.830, avg_batch_time = 119.081\n",
            "Batch: 1-8 (133), loss = 15.873, avg_batch_time = 119.097\n",
            "Batch: 1-9 (134), loss = 8.208, avg_batch_time = 119.118\n",
            "Batch: 1-10 (135), loss = 6.314, avg_batch_time = 119.140\n",
            "Batch: 1-11 (136), loss = 10.616, avg_batch_time = 119.165\n",
            "Batch: 1-12 (137), loss = 10.695, avg_batch_time = 119.188\n",
            "Batch: 1-13 (138), loss = 6.262, avg_batch_time = 119.209\n",
            "Batch: 1-14 (139), loss = 4.723, avg_batch_time = 119.229\n",
            "Batch: 1-15 (140), loss = 3.624, avg_batch_time = 119.240\n",
            "Batch: 1-16 (141), loss = 9.286, avg_batch_time = 119.256\n",
            "Batch: 1-17 (142), loss = 3.622, avg_batch_time = 119.273\n",
            "Batch: 1-18 (143), loss = 10.721, avg_batch_time = 119.293\n",
            "Batch: 1-19 (144), loss = 6.514, avg_batch_time = 119.311\n",
            "Batch: 1-20 (145), loss = 9.698, avg_batch_time = 119.331\n",
            "Batch: 1-21 (146), loss = 8.632, avg_batch_time = 119.349\n",
            "Batch: 1-22 (147), loss = 9.339, avg_batch_time = 119.369\n",
            "Batch: 1-23 (148), loss = 7.342, avg_batch_time = 119.388\n",
            "Batch: 1-24 (149), loss = 4.568, avg_batch_time = 119.424\n",
            "Batch: 1-25 (150), loss = 12.992, avg_batch_time = 119.428\n",
            "Batch: 1-26 (151), loss = 6.869, avg_batch_time = 119.433\n",
            "Batch: 1-27 (152), loss = 6.810, avg_batch_time = 119.450\n",
            "Batch: 1-28 (153), loss = 9.706, avg_batch_time = 119.466\n",
            "Batch: 1-29 (154), loss = 10.437, avg_batch_time = 119.480\n",
            "Batch: 1-30 (155), loss = 6.481, avg_batch_time = 119.505\n",
            "Batch: 1-31 (156), loss = 9.946, avg_batch_time = 119.527\n",
            "Batch: 1-32 (157), loss = 17.893, avg_batch_time = 119.550\n",
            "Batch: 1-33 (158), loss = 4.748, avg_batch_time = 119.561\n",
            "Batch: 1-34 (159), loss = 13.033, avg_batch_time = 119.575\n",
            "Batch: 1-35 (160), loss = 4.472, avg_batch_time = 119.585\n",
            "Batch: 1-36 (161), loss = 5.668, avg_batch_time = 119.592\n",
            "Batch: 1-37 (162), loss = 3.927, avg_batch_time = 119.602\n",
            "Batch: 1-38 (163), loss = 15.138, avg_batch_time = 119.610\n",
            "Batch: 1-39 (164), loss = 14.027, avg_batch_time = 119.621\n",
            "Batch: 1-40 (165), loss = 4.887, avg_batch_time = 119.636\n",
            "Batch: 1-41 (166), loss = 4.894, avg_batch_time = 119.653\n",
            "Batch: 1-42 (167), loss = 7.972, avg_batch_time = 119.671\n",
            "Batch: 1-43 (168), loss = 5.027, avg_batch_time = 119.680\n",
            "Batch: 1-44 (169), loss = 9.939, avg_batch_time = 119.689\n",
            "Batch: 1-45 (170), loss = 5.420, avg_batch_time = 119.700\n",
            "Batch: 1-46 (171), loss = 9.016, avg_batch_time = 119.710\n",
            "Batch: 1-47 (172), loss = 10.402, avg_batch_time = 119.714\n",
            "Batch: 1-48 (173), loss = 9.861, avg_batch_time = 119.721\n",
            "Batch: 1-49 (174), loss = 14.244, avg_batch_time = 119.726\n",
            "Batch: 1-50 (175), loss = 7.474, avg_batch_time = 119.728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_esR2Vee0F3b",
        "outputId": "ea83e3ba-86d4-495b-ab21-44f6ab293869"
      },
      "source": [
        "train(data_loader=dataloader, \n",
        "      model=model, \n",
        "      optimizer=OPTIMIZER, \n",
        "      scheduler=SCHEDULER, \n",
        "      total_epochs=10, \n",
        "      save_interval=100, \n",
        "      save_folder=os.path.join(root_dir, 'models'),\n",
        "      loss=LOSS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 epochs in total, 125 batches per epoch\n",
            "Start epoch 0\n",
            "Batch: 0-0 (0), loss = 3.943, avg_batch_time = 154.437\n",
            "Batch: 0-1 (0), loss = 2.725, avg_batch_time = 276.230\n",
            "Batch: 0-2 (0), loss = 11.046, avg_batch_time = 399.578\n",
            "Batch: 0-3 (0), loss = 9.860, avg_batch_time = 521.917\n",
            "Batch: 0-4 (0), loss = 12.751, avg_batch_time = 644.145\n",
            "Batch: 0-5 (0), loss = 7.252, avg_batch_time = 766.314\n",
            "Batch: 0-6 (0), loss = 7.185, avg_batch_time = 890.304\n",
            "Batch: 0-7 (0), loss = 7.130, avg_batch_time = 1012.247\n",
            "Batch: 0-8 (0), loss = 4.522, avg_batch_time = 1134.873\n",
            "Batch: 0-9 (0), loss = 8.529, avg_batch_time = 1255.715\n",
            "Batch: 0-10 (0), loss = 5.453, avg_batch_time = 1376.416\n",
            "Batch: 0-11 (0), loss = 1.983, avg_batch_time = 1496.725\n",
            "Batch: 0-12 (0), loss = 18.831, avg_batch_time = 1618.205\n",
            "Batch: 0-13 (0), loss = 6.627, avg_batch_time = 1739.805\n",
            "Batch: 0-14 (0), loss = 7.120, avg_batch_time = 1864.680\n",
            "Batch: 0-15 (0), loss = 3.252, avg_batch_time = 1988.287\n",
            "Batch: 0-16 (0), loss = 15.135, avg_batch_time = 2112.890\n",
            "Batch: 0-17 (0), loss = 7.592, avg_batch_time = 2237.677\n",
            "Batch: 0-18 (0), loss = 9.577, avg_batch_time = 2361.549\n",
            "Batch: 0-19 (0), loss = 10.670, avg_batch_time = 2485.560\n",
            "Batch: 0-20 (0), loss = 12.722, avg_batch_time = 2607.748\n",
            "Batch: 0-21 (0), loss = 21.368, avg_batch_time = 2730.115\n",
            "Batch: 0-22 (0), loss = 9.239, avg_batch_time = 2853.924\n",
            "Batch: 0-23 (0), loss = 6.992, avg_batch_time = 2977.103\n",
            "Batch: 0-24 (0), loss = 5.047, avg_batch_time = 3098.931\n",
            "Batch: 0-25 (0), loss = 7.577, avg_batch_time = 3220.360\n",
            "Batch: 0-26 (0), loss = 3.947, avg_batch_time = 3341.519\n",
            "Batch: 0-27 (0), loss = 12.285, avg_batch_time = 3463.092\n",
            "Batch: 0-28 (0), loss = 9.219, avg_batch_time = 3583.851\n",
            "Batch: 0-29 (0), loss = 19.451, avg_batch_time = 3699.259\n",
            "Batch: 0-30 (0), loss = 14.090, avg_batch_time = 3817.254\n",
            "Batch: 0-31 (0), loss = 7.554, avg_batch_time = 3935.542\n",
            "Batch: 0-32 (0), loss = 12.604, avg_batch_time = 4053.120\n",
            "Batch: 0-33 (0), loss = 12.334, avg_batch_time = 4168.380\n",
            "Batch: 0-34 (0), loss = 10.173, avg_batch_time = 4287.354\n",
            "Batch: 0-35 (0), loss = 5.885, avg_batch_time = 4404.602\n",
            "Batch: 0-36 (0), loss = 6.553, avg_batch_time = 4523.087\n",
            "Batch: 0-37 (0), loss = 11.037, avg_batch_time = 4641.809\n",
            "Batch: 0-38 (0), loss = 3.151, avg_batch_time = 4758.968\n",
            "Batch: 0-39 (0), loss = 9.017, avg_batch_time = 4874.472\n",
            "Batch: 0-40 (0), loss = 2.370, avg_batch_time = 4992.148\n",
            "Batch: 0-41 (0), loss = 2.956, avg_batch_time = 5109.670\n",
            "Batch: 0-42 (0), loss = 2.390, avg_batch_time = 5229.622\n",
            "Batch: 0-43 (0), loss = 8.822, avg_batch_time = 5346.531\n",
            "Batch: 0-44 (0), loss = 6.107, avg_batch_time = 5462.863\n",
            "Batch: 0-45 (0), loss = 11.111, avg_batch_time = 5578.153\n",
            "Batch: 0-46 (0), loss = 6.753, avg_batch_time = 5694.022\n",
            "Batch: 0-47 (0), loss = 16.196, avg_batch_time = 5809.590\n",
            "Batch: 0-48 (0), loss = 10.096, avg_batch_time = 5927.079\n",
            "Batch: 0-49 (0), loss = 7.617, avg_batch_time = 6045.087\n",
            "Batch: 0-50 (0), loss = 9.547, avg_batch_time = 6163.434\n",
            "Batch: 0-51 (0), loss = 9.526, avg_batch_time = 6282.206\n",
            "Batch: 0-52 (0), loss = 6.824, avg_batch_time = 6401.619\n",
            "Batch: 0-53 (0), loss = 6.620, avg_batch_time = 6521.256\n",
            "Batch: 0-54 (0), loss = 23.603, avg_batch_time = 6641.327\n",
            "Batch: 0-55 (0), loss = 17.845, avg_batch_time = 6760.971\n",
            "Batch: 0-56 (0), loss = 6.077, avg_batch_time = 6879.246\n",
            "Batch: 0-57 (0), loss = 8.755, avg_batch_time = 6997.213\n",
            "Batch: 0-58 (0), loss = 14.606, avg_batch_time = 7114.562\n",
            "Batch: 0-59 (0), loss = 11.188, avg_batch_time = 7231.168\n",
            "Batch: 0-60 (0), loss = 4.304, avg_batch_time = 7347.449\n",
            "Batch: 0-61 (0), loss = 5.489, avg_batch_time = 7463.526\n",
            "Batch: 0-62 (0), loss = 8.642, avg_batch_time = 7579.891\n",
            "Batch: 0-63 (0), loss = 7.821, avg_batch_time = 7696.848\n",
            "Batch: 0-64 (0), loss = 10.420, avg_batch_time = 7815.024\n",
            "Batch: 0-65 (0), loss = 8.133, avg_batch_time = 7931.181\n",
            "Batch: 0-66 (0), loss = 10.317, avg_batch_time = 8046.450\n",
            "Batch: 0-67 (0), loss = 10.974, avg_batch_time = 8162.621\n",
            "Batch: 0-68 (0), loss = 14.875, avg_batch_time = 8281.124\n",
            "Batch: 0-69 (0), loss = 15.621, avg_batch_time = 8399.042\n",
            "Batch: 0-70 (0), loss = 10.893, avg_batch_time = 8518.166\n",
            "Batch: 0-71 (0), loss = 7.605, avg_batch_time = 8636.578\n",
            "Batch: 0-72 (0), loss = 6.353, avg_batch_time = 8755.720\n",
            "Batch: 0-73 (0), loss = 11.295, avg_batch_time = 8874.983\n",
            "Batch: 0-74 (0), loss = 13.593, avg_batch_time = 8993.840\n",
            "Batch: 0-75 (0), loss = 12.325, avg_batch_time = 9112.005\n",
            "Batch: 0-76 (0), loss = 12.214, avg_batch_time = 9229.618\n",
            "Batch: 0-77 (0), loss = 6.842, avg_batch_time = 9347.248\n",
            "Batch: 0-78 (0), loss = 14.483, avg_batch_time = 9465.615\n",
            "Batch: 0-79 (0), loss = 6.690, avg_batch_time = 9582.082\n",
            "Batch: 0-80 (0), loss = 7.779, avg_batch_time = 9699.539\n",
            "Batch: 0-81 (0), loss = 8.938, avg_batch_time = 9816.420\n",
            "Batch: 0-82 (0), loss = 9.868, avg_batch_time = 9933.693\n",
            "Batch: 0-83 (0), loss = 7.157, avg_batch_time = 10049.119\n",
            "Batch: 0-84 (0), loss = 8.544, avg_batch_time = 10165.343\n",
            "Batch: 0-85 (0), loss = 3.283, avg_batch_time = 10281.708\n",
            "Batch: 0-86 (0), loss = 11.587, avg_batch_time = 10398.698\n",
            "Batch: 0-87 (0), loss = 6.570, avg_batch_time = 10516.372\n",
            "Batch: 0-88 (0), loss = 5.003, avg_batch_time = 10635.085\n",
            "Batch: 0-89 (0), loss = 11.737, avg_batch_time = 10753.863\n",
            "Batch: 0-90 (0), loss = 14.460, avg_batch_time = 10872.975\n",
            "Batch: 0-91 (0), loss = 11.999, avg_batch_time = 10992.463\n",
            "Batch: 0-92 (0), loss = 5.126, avg_batch_time = 11110.914\n",
            "Batch: 0-93 (0), loss = 6.469, avg_batch_time = 11227.866\n",
            "Batch: 0-94 (0), loss = 10.869, avg_batch_time = 11345.616\n",
            "Batch: 0-95 (0), loss = 11.272, avg_batch_time = 11463.547\n",
            "Batch: 0-96 (0), loss = 7.973, avg_batch_time = 11580.652\n",
            "Batch: 0-97 (0), loss = 7.679, avg_batch_time = 11698.642\n",
            "Batch: 0-98 (0), loss = 8.689, avg_batch_time = 11817.571\n",
            "Batch: 0-99 (0), loss = 8.054, avg_batch_time = 11935.931\n",
            "Batch: 0-100 (0), loss = 10.952, avg_batch_time = 12052.486\n",
            "Batch: 0-101 (0), loss = 10.131, avg_batch_time = 12169.001\n",
            "Batch: 0-102 (0), loss = 9.452, avg_batch_time = 12286.696\n",
            "Batch: 0-103 (0), loss = 8.852, avg_batch_time = 12405.353\n",
            "Batch: 0-104 (0), loss = 11.331, avg_batch_time = 12522.711\n",
            "Batch: 0-105 (0), loss = 9.178, avg_batch_time = 12638.024\n",
            "Batch: 0-106 (0), loss = 4.890, avg_batch_time = 12757.006\n",
            "Batch: 0-107 (0), loss = 4.910, avg_batch_time = 12874.416\n",
            "Batch: 0-108 (0), loss = 13.430, avg_batch_time = 12991.021\n",
            "Batch: 0-109 (0), loss = 12.236, avg_batch_time = 13107.558\n",
            "Batch: 0-110 (0), loss = 9.745, avg_batch_time = 13223.812\n",
            "Batch: 0-111 (0), loss = 5.156, avg_batch_time = 13341.634\n",
            "Batch: 0-112 (0), loss = 12.458, avg_batch_time = 13460.325\n",
            "Batch: 0-113 (0), loss = 11.980, avg_batch_time = 13579.588\n",
            "Batch: 0-114 (0), loss = 5.829, avg_batch_time = 13698.541\n",
            "Batch: 0-115 (0), loss = 8.349, avg_batch_time = 13817.098\n",
            "Batch: 0-116 (0), loss = 16.311, avg_batch_time = 13934.941\n",
            "Batch: 0-117 (0), loss = 11.912, avg_batch_time = 14050.413\n",
            "Batch: 0-118 (0), loss = 13.321, avg_batch_time = 14166.151\n",
            "Batch: 0-119 (0), loss = 3.000, avg_batch_time = 14282.292\n",
            "Batch: 0-120 (0), loss = 20.766, avg_batch_time = 14399.235\n",
            "Batch: 0-121 (0), loss = 15.067, avg_batch_time = 14517.053\n",
            "Batch: 0-122 (0), loss = 13.017, avg_batch_time = 14635.661\n",
            "Batch: 0-123 (0), loss = 2.857, avg_batch_time = 14753.709\n",
            "Batch: 0-124 (0), loss = 1.249, avg_batch_time = 14783.582\n",
            "lr = [9.801e-05]\n",
            "Start epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:573: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch: 1-0 (125), loss = 8.970, avg_batch_time = 118.433\n",
            "Batch: 1-1 (125), loss = 9.017, avg_batch_time = 119.384\n",
            "Batch: 1-2 (125), loss = 5.375, avg_batch_time = 120.337\n",
            "Batch: 1-3 (125), loss = 7.075, avg_batch_time = 121.284\n",
            "Batch: 1-4 (125), loss = 7.481, avg_batch_time = 122.229\n",
            "Batch: 1-5 (125), loss = 1.734, avg_batch_time = 123.177\n",
            "Batch: 1-6 (125), loss = 19.267, avg_batch_time = 124.127\n",
            "Batch: 1-7 (125), loss = 19.820, avg_batch_time = 125.075\n",
            "Batch: 1-8 (125), loss = 10.516, avg_batch_time = 126.022\n",
            "Batch: 1-9 (125), loss = 10.060, avg_batch_time = 126.974\n",
            "Batch: 1-10 (125), loss = 7.029, avg_batch_time = 127.918\n",
            "Batch: 1-11 (125), loss = 9.782, avg_batch_time = 128.862\n",
            "Batch: 1-12 (125), loss = 17.294, avg_batch_time = 129.816\n",
            "Batch: 1-13 (125), loss = 9.519, avg_batch_time = 130.759\n",
            "Batch: 1-14 (125), loss = 24.435, avg_batch_time = 131.705\n",
            "Batch: 1-15 (125), loss = 10.206, avg_batch_time = 132.658\n",
            "Batch: 1-16 (125), loss = 11.990, avg_batch_time = 133.606\n",
            "Batch: 1-17 (125), loss = 7.579, avg_batch_time = 134.554\n",
            "Batch: 1-18 (125), loss = 10.911, avg_batch_time = 135.499\n",
            "Batch: 1-19 (125), loss = 6.776, avg_batch_time = 136.438\n",
            "Batch: 1-20 (125), loss = 8.740, avg_batch_time = 137.390\n",
            "Batch: 1-21 (125), loss = 22.785, avg_batch_time = 138.333\n",
            "Batch: 1-22 (125), loss = 15.713, avg_batch_time = 139.275\n",
            "Batch: 1-23 (125), loss = 10.521, avg_batch_time = 140.214\n",
            "Batch: 1-24 (125), loss = 3.664, avg_batch_time = 141.149\n",
            "Batch: 1-25 (125), loss = 5.031, avg_batch_time = 142.087\n",
            "Batch: 1-26 (125), loss = 5.741, avg_batch_time = 143.021\n",
            "Batch: 1-27 (125), loss = 10.490, avg_batch_time = 143.963\n",
            "Batch: 1-28 (125), loss = 10.864, avg_batch_time = 144.913\n",
            "Batch: 1-29 (125), loss = 6.011, avg_batch_time = 145.856\n",
            "Batch: 1-30 (125), loss = 6.038, avg_batch_time = 146.796\n",
            "Batch: 1-31 (125), loss = 11.267, avg_batch_time = 147.735\n",
            "Batch: 1-32 (125), loss = 6.087, avg_batch_time = 148.677\n",
            "Batch: 1-33 (125), loss = 5.387, avg_batch_time = 149.619\n",
            "Batch: 1-34 (125), loss = 8.858, avg_batch_time = 150.552\n",
            "Batch: 1-35 (125), loss = 6.580, avg_batch_time = 151.491\n",
            "Batch: 1-36 (125), loss = 12.498, avg_batch_time = 152.465\n",
            "Batch: 1-37 (125), loss = 14.855, avg_batch_time = 153.419\n",
            "Batch: 1-38 (125), loss = 11.891, avg_batch_time = 154.368\n",
            "Batch: 1-39 (125), loss = 10.630, avg_batch_time = 155.325\n",
            "Batch: 1-40 (125), loss = 1.616, avg_batch_time = 156.279\n",
            "Batch: 1-41 (125), loss = 4.173, avg_batch_time = 157.238\n",
            "Batch: 1-42 (125), loss = 12.487, avg_batch_time = 158.198\n",
            "Batch: 1-43 (125), loss = 14.267, avg_batch_time = 159.187\n",
            "Batch: 1-44 (125), loss = 19.175, avg_batch_time = 160.142\n",
            "Batch: 1-45 (125), loss = 21.200, avg_batch_time = 161.101\n",
            "Batch: 1-46 (125), loss = 15.731, avg_batch_time = 162.065\n",
            "Batch: 1-47 (125), loss = 7.447, avg_batch_time = 163.032\n",
            "Batch: 1-48 (125), loss = 3.327, avg_batch_time = 163.999\n",
            "Batch: 1-49 (125), loss = 4.426, avg_batch_time = 164.969\n",
            "Batch: 1-50 (125), loss = 20.089, avg_batch_time = 165.938\n",
            "Batch: 1-51 (125), loss = 12.976, avg_batch_time = 166.902\n",
            "Batch: 1-52 (125), loss = 12.066, avg_batch_time = 167.863\n",
            "Batch: 1-53 (125), loss = 28.055, avg_batch_time = 168.807\n",
            "Batch: 1-54 (125), loss = 6.699, avg_batch_time = 169.755\n",
            "Batch: 1-55 (125), loss = 10.742, avg_batch_time = 170.688\n",
            "Batch: 1-56 (125), loss = 15.014, avg_batch_time = 171.613\n",
            "Batch: 1-57 (125), loss = 7.621, avg_batch_time = 172.560\n",
            "Batch: 1-58 (125), loss = 10.255, avg_batch_time = 173.515\n",
            "Batch: 1-59 (125), loss = 14.123, avg_batch_time = 174.480\n",
            "Batch: 1-60 (125), loss = 7.433, avg_batch_time = 175.418\n",
            "Batch: 1-61 (125), loss = 8.840, avg_batch_time = 176.349\n",
            "Batch: 1-62 (125), loss = 7.155, avg_batch_time = 177.287\n",
            "Batch: 1-63 (125), loss = 3.224, avg_batch_time = 178.215\n",
            "Batch: 1-64 (125), loss = 5.761, avg_batch_time = 179.146\n",
            "Batch: 1-65 (125), loss = 7.330, avg_batch_time = 180.076\n",
            "Batch: 1-66 (125), loss = 28.509, avg_batch_time = 181.006\n",
            "Batch: 1-67 (125), loss = 6.794, avg_batch_time = 181.933\n",
            "Batch: 1-68 (125), loss = 9.074, avg_batch_time = 182.861\n",
            "Batch: 1-69 (125), loss = 17.458, avg_batch_time = 183.792\n",
            "Batch: 1-70 (125), loss = 7.193, avg_batch_time = 184.722\n",
            "Batch: 1-71 (125), loss = 8.343, avg_batch_time = 185.652\n",
            "Batch: 1-72 (125), loss = 11.886, avg_batch_time = 186.588\n",
            "Batch: 1-73 (125), loss = 7.497, avg_batch_time = 187.524\n",
            "Batch: 1-74 (125), loss = 7.446, avg_batch_time = 188.453\n",
            "Batch: 1-75 (125), loss = 6.080, avg_batch_time = 189.383\n",
            "Batch: 1-76 (125), loss = 3.516, avg_batch_time = 190.308\n",
            "Batch: 1-77 (125), loss = 8.446, avg_batch_time = 191.228\n",
            "Batch: 1-78 (125), loss = 7.170, avg_batch_time = 192.154\n",
            "Batch: 1-79 (125), loss = 12.979, avg_batch_time = 193.121\n",
            "Batch: 1-80 (125), loss = 4.985, avg_batch_time = 194.091\n",
            "Batch: 1-81 (125), loss = 2.241, avg_batch_time = 195.055\n",
            "Batch: 1-82 (125), loss = 17.793, avg_batch_time = 196.025\n",
            "Batch: 1-83 (125), loss = 4.345, avg_batch_time = 196.991\n",
            "Batch: 1-84 (125), loss = 4.156, avg_batch_time = 197.964\n",
            "Batch: 1-85 (125), loss = 9.030, avg_batch_time = 198.943\n",
            "Batch: 1-86 (125), loss = 16.622, avg_batch_time = 199.929\n",
            "Batch: 1-87 (125), loss = 9.786, avg_batch_time = 200.917\n",
            "Batch: 1-88 (125), loss = 10.647, avg_batch_time = 201.905\n",
            "Batch: 1-89 (125), loss = 7.713, avg_batch_time = 202.892\n",
            "Batch: 1-90 (125), loss = 12.738, avg_batch_time = 203.878\n",
            "Batch: 1-91 (125), loss = 15.905, avg_batch_time = 204.863\n",
            "Batch: 1-92 (125), loss = 4.497, avg_batch_time = 205.853\n",
            "Batch: 1-93 (125), loss = 12.205, avg_batch_time = 206.844\n",
            "Batch: 1-94 (125), loss = 15.026, avg_batch_time = 207.834\n",
            "Batch: 1-95 (125), loss = 7.455, avg_batch_time = 208.824\n",
            "Batch: 1-96 (125), loss = 2.789, avg_batch_time = 209.813\n",
            "Batch: 1-97 (125), loss = 11.011, avg_batch_time = 210.804\n",
            "Batch: 1-98 (125), loss = 6.021, avg_batch_time = 211.790\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-7c8528f13067>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0msave_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0msave_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m       loss=LOSS)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-4e77d3c827d0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_loader, model, optimizer, scheduler, total_epochs, save_interval, save_folder, loss)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;31m# add fake channel dimension as 5-D input is expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;31m# calculating loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/resnet_for_multimodal_regression.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/resnet_for_multimodal_regression.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    584\u001b[0m             )\n\u001b[1;32m    585\u001b[0m         return F.conv3d(\n\u001b[0;32m--> 586\u001b[0;31m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m         )\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uWJoqpSl3xg2",
        "outputId": "54cbe701-48da-4bc5-ea79-07e0a6723ff5"
      },
      "source": [
        "lmbda = lambda epoch: 1.00\n",
        "scheduler_toy = lr_scheduler.MultiplicativeLR(OPTIMIZER, lr_lambda=lmbda)\n",
        "train(data_loader=dataloader_toy, \n",
        "      model=model, \n",
        "      optimizer=OPTIMIZER, \n",
        "      scheduler=scheduler_toy,\n",
        "      total_epochs=1000, \n",
        "      save_interval=100, \n",
        "      save_folder=os.path.join(root_dir, 'models'),\n",
        "      loss=LOSS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 epochs in total, 1 batches per epoch\n",
            "Start epoch 0\n",
            "Batch: 0-0 (0), loss = 6.230, avg_batch_time = 140.363\n",
            "lr = [1e-05]\n",
            "Start epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:325: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch: 1-0 (1), loss = 6.179, avg_batch_time = 133.846\n",
            "lr = [1e-05]\n",
            "Start epoch 2\n",
            "Batch: 2-0 (2), loss = 6.086, avg_batch_time = 131.606\n",
            "lr = [1e-05]\n",
            "Start epoch 3\n",
            "Batch: 3-0 (3), loss = 5.963, avg_batch_time = 130.472\n",
            "lr = [1e-05]\n",
            "Start epoch 4\n",
            "Batch: 4-0 (4), loss = 5.820, avg_batch_time = 129.705\n",
            "lr = [1e-05]\n",
            "Start epoch 5\n",
            "Batch: 5-0 (5), loss = 5.673, avg_batch_time = 129.202\n",
            "lr = [1e-05]\n",
            "Start epoch 6\n",
            "Batch: 6-0 (6), loss = 5.531, avg_batch_time = 128.844\n",
            "lr = [1e-05]\n",
            "Start epoch 7\n",
            "Batch: 7-0 (7), loss = 5.401, avg_batch_time = 128.569\n",
            "lr = [1e-05]\n",
            "Start epoch 8\n",
            "Batch: 8-0 (8), loss = 5.288, avg_batch_time = 128.373\n",
            "lr = [1e-05]\n",
            "Start epoch 9\n",
            "Batch: 9-0 (9), loss = 5.195, avg_batch_time = 128.223\n",
            "lr = [1e-05]\n",
            "Start epoch 10\n",
            "Batch: 10-0 (10), loss = 5.124, avg_batch_time = 128.019\n",
            "lr = [1e-05]\n",
            "Start epoch 11\n",
            "Batch: 11-0 (11), loss = 5.073, avg_batch_time = 127.770\n",
            "lr = [1e-05]\n",
            "Start epoch 12\n",
            "Batch: 12-0 (12), loss = 5.039, avg_batch_time = 127.173\n",
            "lr = [1e-05]\n",
            "Start epoch 13\n",
            "Batch: 13-0 (13), loss = 5.019, avg_batch_time = 126.664\n",
            "lr = [1e-05]\n",
            "Start epoch 14\n",
            "Batch: 14-0 (14), loss = 5.009, avg_batch_time = 126.188\n",
            "lr = [1e-05]\n",
            "Start epoch 15\n",
            "Batch: 15-0 (15), loss = 5.004, avg_batch_time = 125.754\n",
            "lr = [1e-05]\n",
            "Start epoch 16\n",
            "Batch: 16-0 (16), loss = 5.000, avg_batch_time = 125.404\n",
            "lr = [1e-05]\n",
            "Start epoch 17\n",
            "Batch: 17-0 (17), loss = 4.994, avg_batch_time = 125.075\n",
            "lr = [1e-05]\n",
            "Start epoch 18\n",
            "Batch: 18-0 (18), loss = 4.985, avg_batch_time = 124.724\n",
            "lr = [1e-05]\n",
            "Start epoch 19\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-e53f96525e92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0msave_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0msave_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'models'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m       loss=LOSS)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-5bbab491cd8c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_loader, model, optimizer, scheduler, total_epochs, save_interval, save_folder, loss)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# add fake channel dimension as 5-D input is expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# calculating loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/resnet_for_multimodal_regression.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/resnet_for_multimodal_regression.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    584\u001b[0m             )\n\u001b[1;32m    585\u001b[0m         return F.conv3d(\n\u001b[0;32m--> 586\u001b[0;31m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m         )\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMoiNjqP2GPK",
        "outputId": "b49bb81a-176d-45f2-cb4d-cb3c3b652be1"
      },
      "source": [
        "model(med[0]['scan'].unsqueeze(0).unsqueeze(0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1229]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFTX-QtH2UWA",
        "outputId": "8567c7aa-336b-438a-e0eb-dd757906b2b4"
      },
      "source": [
        "(med[0]['icp'] - 15) / 11"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.5909090909090909"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqbr8MCR2QPH",
        "outputId": "e2d4c16b-7652-4416-a31f-33c755f870ed"
      },
      "source": [
        "model2 = resnet.resnet10(sample_input_D=128,\n",
        "                 sample_input_H=128,\n",
        "                 sample_input_W=512)\n",
        "model2(med[0]['scan'].unsqueeze(0).unsqueeze(0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/resnet_for_multimodal_regression.py:148: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
            "  m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0331]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKdEfVOkAeGN",
        "outputId": "4968a937-366d-460d-e2f7-4ef1dfe6246f"
      },
      "source": [
        "LOSS(torch.tensor(32.), torch.tensor(1.))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(961.)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukaopcaWAUib",
        "outputId": "4020efbb-62e1-44bb-c87b-b316e1eb7865"
      },
      "source": [
        "model(med[0]['scan'].unsqueeze(0).unsqueeze(0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-18131.1230]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeInItT26tRI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 934,
          "referenced_widgets": [
            "1496e60de8d24b4a9d17dcfeb9c7468c",
            "a4ad52d0565d4007b31d321dd7e295c2",
            "afd99994c80b431f9b034c035ac64c29",
            "c82491a67a0242ad8e0943a9b3c41f0f",
            "7c55161733e84756b75a86b01f8419a2",
            "a74b84fa8bfe4fe89508943e5ec2fa2d",
            "4d19efdd722f4ec59e67121984f2c34b",
            "d49f2bea19f44779a94c96cfd8bbfdff",
            "7eb37ec414c04494a33121b9bf53d696",
            "9705665c5ca84464af003c1b95291400",
            "0cc5cc7b2253455996fde91c81654075",
            "c0fce71959974420bc56c5b018d75c3c",
            "86c383bf6e194b058a3bd94afd3575eb",
            "fb80c9ee148d4f04ad2d2339f48a5aac",
            "96163615670c4621b23d650dd6e580be",
            "7fd094effb224ea6a93484ec148b3dc5",
            "3b133e0c0b21430ca4e1067fe62b65a8",
            "2ff1890e282f4f4589a4155cd055f416",
            "36802fa0bab34d7bbb2d0e2d66379d2e",
            "b1a027d26a584ba386d4d85081d1fbc2",
            "78e4e55559ea46f9b3f32f4a62bc1346",
            "7ff7fef92e2743838aa75d043e264f94"
          ]
        },
        "outputId": "9594bc8c-4a38-421b-a42b-44ab437fac72"
      },
      "source": [
        "import torch \n",
        "import torchvision\n",
        "import torch.nn as nn \n",
        "from IPython.display import Image \n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "seed = 12345\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 7)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "cifar10_train = torchvision.datasets.CIFAR10(root='./cifar10', \n",
        "                                             train=True, \n",
        "                                             transform=None, \n",
        "                                             target_transform=None,\n",
        "                                             download=True)\n",
        "cifar10_test = torchvision.datasets.CIFAR10(root='./cifar10', \n",
        "                                             train=False, \n",
        "                                             transform=None, \n",
        "                                             target_transform=None,\n",
        "                                             download=True)\n",
        "\n",
        "# Divides the dataset into train and val so that we can use the val to choose our hyperparameters\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(cifar10_train, [40000, 10000], \n",
        "                                                           generator=torch.Generator().manual_seed(12345))\n",
        "test_dataset = cifar10_test\n",
        "\n",
        "class MapDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    Given a dataset, creates a dataset which applies a mapping function\n",
        "    to its items (lazily, only when an item is called).\n",
        "\n",
        "    Note that data is not cloned/copied from the initial dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset, map_fn):\n",
        "        self.dataset = dataset\n",
        "        self.map = map_fn\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.map:     \n",
        "            x = self.map(self.dataset[index][0]) \n",
        "        else:     \n",
        "            x = self.dataset[index][0]  \n",
        "        y = self.dataset[index][1]         \n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "# Notice that we apply the same mean and std normalization calculated on train, to both the train and test datasets.\n",
        "test_transform = transforms.Compose([\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize(\n",
        "                                         [0.4373, 0.4434, 0.4725],\n",
        "                                         [0.1201, 0.1231, 0.1052])\n",
        "                                     ])\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize(\n",
        "                                          [0.4373, 0.4434, 0.4725],\n",
        "                                          [0.1201, 0.1231, 0.1052])\n",
        "                                      ])\n",
        "\n",
        "train_dataset_w_transform  = MapDataset(train_dataset, train_transform)\n",
        "val_dataset_w_transform = MapDataset(val_dataset, test_transform)\n",
        "test_dataset_w_transform = MapDataset(test_dataset, test_transform)\n",
        "\n",
        "bs = 128\n",
        "torch.backends.cudnn.benchmark = True\n",
        "train_loader = DataLoader(train_dataset_w_transform, batch_size=bs, shuffle=True, drop_last=False,num_workers=10, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset_w_transform, batch_size=bs, shuffle=False, drop_last=False,num_workers=10, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset_w_transform, batch_size=bs, shuffle=False, drop_last=False,num_workers=10, pin_memory=True)\n",
        "\n",
        "def train_loop(model, criterion, optimizer,  train_loader, val_loader, device):\n",
        "    \"\"\"\n",
        "    Generic training loop\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : Object instance of your model class \n",
        "    criterion : Loss function \n",
        "    optimizer : Instance of optimizer class of your choice \n",
        "    train_loader : Training data loader \n",
        "    val_loader : Validation data loader\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    train_losses : List with train loss on dataset per epoch\n",
        "    train_accuracies : List with train accuracy on dataset per epoch\n",
        "    val_losses : List with validation loss on dataset per epoch\n",
        "    val_accuracies : List with validation accuracy on dataset per epoch\n",
        "\n",
        "    \"\"\"\n",
        "    best_val = 0.0\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "    max_patience = 5\n",
        "    patience_counter = 0\n",
        "\n",
        "    # Training\n",
        "    for t in tqdm(range(50)):\n",
        "        # TODO : Set the model to train mode        \n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        correct = 0\n",
        "        n = 0\n",
        "        # TODO: Loop over the training set \n",
        "        for batch_idx, samples in enumerate(train_loader):\n",
        "            # TODO: Put the inputs and targets on the write device\n",
        "            image = samples[0].to(device)\n",
        "            label = samples[1].to(device)\n",
        "            # TODO: Feed forward to get the logits\n",
        "            output = model(image)\n",
        "            _, preds = torch.max(output, dim = 1)\n",
        "            # TODO: Compute the loss and accuracy\n",
        "            loss = criterion(output, label)\n",
        "            # TODO: zero the gradients before running\n",
        "            # the backward pass.\n",
        "            optimizer.zero_grad()\n",
        "            # TODO: Backward pass to compute the gradient\n",
        "            # of loss w.r.t our learnable params. \n",
        "            loss.backward()\n",
        "            # TODO: Update params\n",
        "            optimizer.step()\n",
        "            # TODO: Keep track of accuracy and loss\n",
        "            train_loss += loss.item()\n",
        "            n += image.shape[0]\n",
        "            correct += torch.sum(preds == label).item()\n",
        "        \n",
        "        train_losses.append(train_loss / n)\n",
        "        train_accuracies.append(correct / n)\n",
        "        \n",
        "        # TODO: Switch the model to eval mode\n",
        "        model.eval()\n",
        "\n",
        "        val_loss = 0\n",
        "        val_correct = 0\n",
        "        val_n = 0\n",
        "        with torch.no_grad():\n",
        "            # TODO: Loop over the validation set \n",
        "            for batch_idx, samples in enumerate(val_loader):\n",
        "                # TODO: Put the inputs and targets on the write device\n",
        "                image = samples[0].to(device)\n",
        "                label = samples[1].to(device)\n",
        "                # TODO: Feed forward to get the logits\n",
        "                output = model(image)\n",
        "                _, preds = torch.max(output, dim=1)\n",
        "                # TODO: Compute the loss and accuracy\n",
        "                loss = criterion(output, label)\n",
        "                # TODO: Keep track of accuracy and loss\n",
        "                val_loss += loss.item()\n",
        "                val_n += image.shape[0]\n",
        "                val_correct += torch.sum(preds == label).item()\n",
        "            val_losses.append(val_loss / val_n)\n",
        "            val_accuracies.append(val_correct / val_n)\n",
        "                \n",
        "        if val_accuracies[-1] > best_val:\n",
        "            best_val = val_accuracies[-1]\n",
        "            patience_counter = 0\n",
        "            # TODO: Save best model, optimizer, epoch_number\n",
        "            checkpoint = {\n",
        "                'model':model.state_dict(),\n",
        "                'epoch':t,\n",
        "                'optimizer':optimizer.state_dict()\n",
        "            }\n",
        "            torch.save(checkpoint, 'checkpoint.pth')\n",
        "            \n",
        "        else:\n",
        "            patience_counter += 1    \n",
        "            if patience_counter > max_patience: \n",
        "                break\n",
        "\n",
        "        print(\"[EPOCH]: %i, [TRAIN LOSS]: %.6f, [TRAIN ACCURACY]: %.3f\" % (t, train_losses[-1], train_accuracies[-1]))\n",
        "        print(\"[EPOCH]: %i, [VAL LOSS]: %.6f, [VAL ACCURACY]: %.3f \\n\" % (t, val_losses[-1] ,val_accuracies[-1]))\n",
        "\n",
        "    return train_losses, train_accuracies, val_losses, val_accuracies\n",
        "\n",
        "class View(nn.Module):\n",
        "    def __init__(self, shape):\n",
        "        super().__init__()\n",
        "        self.shape = shape\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x.view(*self.shape)\n",
        "\n",
        "ShallowNet =  nn.Sequential(\n",
        "      nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size=5, padding=2),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2),\n",
        "      nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2),\n",
        "      nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size=3, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=8),\n",
        "      View((-1,256)),\n",
        "      nn.Linear(256, 10),\n",
        ")\n",
        "\n",
        "class ShallowConvnet(nn.Module):\n",
        "    def __init__(self, input_channels, num_classes):\n",
        "        \"\"\"\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_channels : Number of input channels\n",
        "        num_classes : Number of classes for the final prediction \n",
        "        \"\"\"\n",
        "        \n",
        "        # TODO\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(in_channels = input_channels, out_channels = 64, kernel_size=5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=8),\n",
        "            View((-1,256)),\n",
        "            nn.Linear(256, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        output : Result after running through the model\n",
        "        \"\"\"\n",
        "        \n",
        "        # TODO\n",
        "        return self.model(x)\n",
        "\n",
        "# TODO : Initialize the model and cast to correct device\n",
        "model = ShallowConvnet(input_channels=3, num_classes=10)\n",
        "model.to(device)\n",
        "# TODO : Initialize the criterion\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# TODO : Initialize the SGD optimizer with lr 1e-3\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
        "\n",
        "# TODO : Run the training loop using this model\n",
        "loss_train, acc_train, loss_val, acc_val = train_loop(model,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar10/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1496e60de8d24b4a9d17dcfeb9c7468c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./cifar10/cifar-10-python.tar.gz to ./cifar10\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0fce71959974420bc56c5b018d75c3c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EPOCH]: 0, [TRAIN LOSS]: 0.017868, [TRAIN ACCURACY]: 0.133\n",
            "[EPOCH]: 0, [VAL LOSS]: 0.017815, [VAL ACCURACY]: 0.161 \n",
            "\n",
            "[EPOCH]: 1, [TRAIN LOSS]: 0.017435, [TRAIN ACCURACY]: 0.214\n",
            "[EPOCH]: 1, [VAL LOSS]: 0.017377, [VAL ACCURACY]: 0.247 \n",
            "\n",
            "[EPOCH]: 2, [TRAIN LOSS]: 0.016973, [TRAIN ACCURACY]: 0.260\n",
            "[EPOCH]: 2, [VAL LOSS]: 0.016897, [VAL ACCURACY]: 0.261 \n",
            "\n",
            "[EPOCH]: 3, [TRAIN LOSS]: 0.016488, [TRAIN ACCURACY]: 0.277\n",
            "[EPOCH]: 3, [VAL LOSS]: 0.016421, [VAL ACCURACY]: 0.284 \n",
            "\n",
            "[EPOCH]: 4, [TRAIN LOSS]: 0.016030, [TRAIN ACCURACY]: 0.292\n",
            "[EPOCH]: 4, [VAL LOSS]: 0.015975, [VAL ACCURACY]: 0.296 \n",
            "\n",
            "[EPOCH]: 5, [TRAIN LOSS]: 0.015633, [TRAIN ACCURACY]: 0.305\n",
            "[EPOCH]: 5, [VAL LOSS]: 0.015607, [VAL ACCURACY]: 0.308 \n",
            "\n",
            "[EPOCH]: 6, [TRAIN LOSS]: 0.015302, [TRAIN ACCURACY]: 0.317\n",
            "[EPOCH]: 6, [VAL LOSS]: 0.015293, [VAL ACCURACY]: 0.316 \n",
            "\n",
            "[EPOCH]: 7, [TRAIN LOSS]: 0.015010, [TRAIN ACCURACY]: 0.327\n",
            "[EPOCH]: 7, [VAL LOSS]: 0.015011, [VAL ACCURACY]: 0.324 \n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-a0fb9bf87ccd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m     device)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-42-a0fb9bf87ccd>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(model, criterion, optimizer, train_loader, val_loader, device)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# TODO: Loop over the validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0;31m# TODO: Put the inputs and targets on the write device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8uoRzCf81Xj",
        "outputId": "fb9d6b30-9ae3-4b95-f304-43cf3df08bfc"
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gputil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=61a3a59f66b8151048a6cd17fcafa54a158b57f841edc22e3c1d1aca2c53e458\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Gen RAM Free: 25.6 GB  | Proc size: 10.8 GB\n",
            "GPU RAM Free: 14907MB | Used: 1373MB | Util   8% | Total 16280MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaC9VK_89gEN",
        "outputId": "403ac332-bc78-4aa7-ca20-f03e2d588ffb"
      },
      "source": [
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "    print('Memory Usage:')\n",
        "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla P100-PCIE-16GB\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.3 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/cuda/memory.py:386: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
            "  FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9w7vsDY9nTz",
        "outputId": "e577c099-281e-4e8e-f439-c92f3d99a711"
      },
      "source": [
        "# Import packages\n",
        "import os,sys,humanize,psutil,GPUtil\n",
        "\n",
        "def mem_report():\n",
        "  print(\"CPU RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ))\n",
        "  \n",
        "  GPUs = GPUtil.getGPUs()\n",
        "  for i, gpu in enumerate(GPUs):\n",
        "    print('GPU {:d} ... Mem Free: {:.0f}MB / {:.0f}MB | Utilization {:3.0f}%'.format(i, gpu.memoryFree, gpu.memoryTotal, gpu.memoryUtil*100))\n",
        "    \n",
        "# Execute function\n",
        "mem_report()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU RAM Free: 25.6 GB\n",
            "GPU 0 ... Mem Free: 14907MB / 16280MB | Utilization   8%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHZ3U10v9tUc",
        "outputId": "9c1dcee4-35b1-429c-c48e-284e6d94b3b3"
      },
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "wide_resnet50_2 = models.wide_resnet50_2(pretrained=True)\n",
        "if torch.cuda.is_available():\n",
        "  wide_resnet50_2.cuda()\n",
        "\n",
        "mem_report()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU RAM Free: 25.6 GB\n",
            "GPU 0 ... Mem Free: 14901MB / 16280MB | Utilization   8%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJXICDwG9zAP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}